{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph:\n",
    "    \n",
    "    # model parameters\n",
    "    m = None\n",
    "    delta_repr = None # this is delta / m\n",
    "\n",
    "    # graph state\n",
    "    current_timestep = 0        \n",
    "\n",
    "    '''\n",
    "    initializes the PAM\n",
    "    @param m >=1, number of edges added each timestep\n",
    "    @param delta >= -m, determines the growth rule\n",
    "    @param t >= 1, number of timesteps\n",
    "    @argument recursive=False, there are no benefits to recursive implementation, it is limited by the recursion depth. \n",
    "                                but I'm still keeping it in, sue me.\n",
    "    @constraint: delta >= -m\n",
    "    '''\n",
    "    def __init__(self, m, delta, t):\n",
    "        assert delta >= -m, \"parameter delta has to be >= -m\"\n",
    "\n",
    "        self.delta_repr = delta / m\n",
    "        self.m = m\n",
    "        \n",
    "        #political orientation\n",
    "        self.ors = np.array(['gop', 'ind', 'dem'])\n",
    "        self.votes = np.zeros(t).astype('str')\n",
    "\n",
    "        # the representation of the PAM in terms of PAM with m = 1.\n",
    "        self.G_repr = nx.Graph()\n",
    "\n",
    "        #self.degr_distr = {}\n",
    "        self.degr_distr = np.array([])\n",
    "        \n",
    "        self.iterativeGrowth(t)\n",
    "\n",
    "    def growFurther(self, t):\n",
    "        assert t >= self.current_timestep, \"timestep given in recursiveGrowth is less than current timestep.\"\n",
    "        self.iterativeGrowth(t)\n",
    "        \n",
    "    def growCoex(self, t):\n",
    "        assert t >= self.current_timestep\n",
    "        self.coexGrowth(t) \n",
    "        \n",
    "    '''\n",
    "    iteratively grow G_repr until it has self.m*t nodes\n",
    "    '''\n",
    "    def iterativeGrowth(self, t):\n",
    "        for i in tqdm(range(self.G_repr.number_of_nodes(), self.m*t)):\n",
    "            # add new vertex (first vertex is called \"0\")\n",
    "            self.G_repr.add_node(i)\n",
    "\n",
    "            # add the appropriate edge with the heuristic  (8.2.1)\n",
    "            self._addConnection()\n",
    "\n",
    "        self.current_timestep = t\n",
    "        self._collapseGraph()\n",
    "        \n",
    "    def coexGrowth(self, t):\n",
    "        for i in tqdm(range(self.G.number_of_nodes(), t)):\n",
    "            # add new vertex (first vertex is called \"0\")\n",
    "            self.G_repr.add_nodes_from(np.arange(self.m) + self.m*i)\n",
    "            \n",
    "            # add the appropriate edge with the heuristic  (8.2.1)\n",
    "            self._coexConnection()\n",
    "\n",
    "        self.current_timestep = t\n",
    "        self._coexcollapseGraph()\n",
    "        \n",
    "\n",
    "    def _addConnection(self):\n",
    "        # self loop probability\n",
    "        dists = np.append(self.degr_distr, 1 + self.delta_repr)\n",
    "        # select randomly the name of another vertex\n",
    "        secondEndpoint = np.random.choice(len(dists), p = dists/np.sum(dists))\n",
    "                      \n",
    "        # maintain degree distr\n",
    "        self.degr_distr = dists\n",
    "        self.degr_distr[secondEndpoint] += 1\n",
    "\n",
    "        # update self.G\n",
    "        self.G_repr.add_edge(len(dists)-1, secondEndpoint)\n",
    "        \n",
    "    def _coexConnection(self):\n",
    "        choices = np.array([])\n",
    "        for i in range(self.m):\n",
    "            # self loop probability\n",
    "            dists = np.append(self.degr_distr, 1 + self.delta_repr)\n",
    "\n",
    "            # select randomly the name of another vertex\n",
    "            secondEndpoint = np.random.choice(len(dists), p = dists/np.sum(dists))\n",
    "\n",
    "            #copy the type of the other vertex\n",
    "            if secondEndpoint//self.m < len(self.votes):\n",
    "                choices = np.append(choices, self.votes[secondEndpoint//self.m])\n",
    "            else:\n",
    "                choices = np.append(choices, 'ind') \n",
    "            \n",
    "            # maintain degree distr\n",
    "            self.degr_distr = dists\n",
    "            self.degr_distr[secondEndpoint] += 1\n",
    "\n",
    "            # update self.G\n",
    "            self.G_repr.add_edge(len(dists)-1, secondEndpoint)\n",
    "        vote = np.append(self.votes, np.random.choice(choices, p = np.ones(len(choices))/len(choices)))\n",
    "        self.votes = vote\n",
    "        \n",
    "    \n",
    "\n",
    "    ''' \n",
    "    Explictely calculate the probabilities of attachment for each node. \n",
    "    '''\n",
    "    def _calculateConnectionPMF(self):\n",
    "        local_t = self.G_repr.number_of_nodes() - 1\n",
    "        probabilities = np.zeros(self.G_repr.number_of_nodes())\n",
    "\n",
    "        # self loop probability  (1 + δ)/(local_t(2 + δ) + (1 + δ))\n",
    "        probabilities[-1] = (1 + self.delta_repr) / (local_t*(2 + self.delta_repr) + (1 + self.delta_repr))\n",
    "\n",
    "        # other vertices probabilities:  (vertex_degr + δ)/(local_t(2 + δ) + (1 + δ))\n",
    "        for i in range(len(probabilities)-1):\n",
    "\n",
    "            # find degree of vertex with a self loop counting double\n",
    "            adj = self.G_repr.adj[i] \n",
    "            vertex_degr = len(adj)+1 if (i in adj.keys()) else len(adj)\n",
    "\n",
    "            probabilities[i]  = (vertex_degr + self.delta_repr)/(local_t*(2 + self.delta_repr) + (1 + self.delta_repr))\n",
    "\n",
    "        \n",
    "        assert abs(sum(probabilities) - 1) < 0.00001, \"PMF does not sum to 1, but to {}\".format(sum(probabilities))\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    '''\n",
    "    (PAM_m,delta)_t is defined in terms of(PAM_1,delta/m)_mt.\n",
    "    Thus to get the (PAM_m,delta)_t, the alternative representation has to be collapsed.\n",
    "    '''\n",
    "    def _collapseGraph1(self):\n",
    "        if self.m == 1:\n",
    "            self.G = self.G_repr\n",
    "        else:\n",
    "            # collapses G_repr into G\n",
    "            self.G = nx.Graph()\n",
    "\n",
    "            # add t vertices \n",
    "            for i in range(self.current_timestep):\n",
    "                self.G.add_node(i)\n",
    "            \n",
    "            for i in range(self.current_timestep): # i denotes the collapsed vertex\n",
    "                for j in range(self.m): # j iterates through \n",
    "                    vertex_index = i*self.m + j\n",
    "\n",
    "                    # loop through the adjacent vertices\n",
    "                    for adj_vertex in self.G_repr.adj[vertex_index].keys():\n",
    "\n",
    "                        # find the name of the collapsed vertex\n",
    "                        adj_vertex_collapsed = (adj_vertex // self.m)\n",
    "\n",
    "                        # add edge to the collapsed graph\n",
    "                        self.G.add_edge(i, adj_vertex_collapsed)\n",
    "\n",
    "    def _collapseGraph(self):\n",
    "        self.G = nx.Graph()\n",
    "        self.G.add_nodes_from(np.arange(self.current_timestep))\n",
    "        for i in range(self.current_timestep):\n",
    "            self.votes[i] = np.random.choice(self.ors, p = [1/3, 1/3, 1/3])\n",
    "            self.G.nodes[i][\"type\"] = self.votes[i]\n",
    "            nodes = np.arange(0, self.m) + self.m*i \n",
    "            edges = list(self.G_repr.edges(nodes))\n",
    "            for edge in edges:\n",
    "                self.G.add_edge(i, edge[1] // self.m)\n",
    "                \n",
    "    def _coexcollapseGraph(self):\n",
    "        self.G = nx.Graph()\n",
    "        self.G.add_nodes_from(np.arange(self.current_timestep))\n",
    "        for i in range(self.current_timestep):\n",
    "            self.G.nodes[i][\"type\"] = self.votes[i]\n",
    "            nodes = np.arange(0, self.m) + self.m*i \n",
    "            edges = list(self.G_repr.edges(nodes))\n",
    "            for edge in edges:\n",
    "                self.G.add_edge(i, edge[1] // self.m)\n",
    "                \n",
    "    \n",
    "    def draw(self):\n",
    "        nx.draw_circular(self.G)\n",
    "        plt.show()\n",
    "        \n",
    "    def draw2(self):\n",
    "        nx.draw_circular(self.G_repr)\n",
    "        plt.show()\n",
    "        \n",
    "    def draw3(self):\n",
    "        color_state_map = {'gop': 'red', 'ind': 'yellow', 'dem': 'blue'}\n",
    "        label = {}\n",
    "        for i in range(self.current_timestep):\n",
    "            label[i] = self.G.nodes[i][\"type\"]\n",
    "        nx.draw_networkx(self.G, node_color=[color_state_map[node[1]['type']] \n",
    "                    for node in self.G.nodes(data=True)], with_labels = True, labels = label)\n",
    "        plt.show()\n",
    "\n",
    "    def draw4(self):\n",
    "        color_state_map = {'gop': 'red', 'ind': 'yellow', 'dem': 'blue'}\n",
    "        nx.draw_networkx(self.G, node_color=[color_state_map[node[1]['type']] \n",
    "                    for node in self.G.nodes(data=True)], with_labels=False)\n",
    "        plt.show()\n",
    "    '''\n",
    "    Returns distribution of typical distance:\n",
    "    - the length of the shortest path between two randomly drawn nodes, given that they are connected\n",
    "    @param sample: The number of randomly drawn \n",
    "    '''\n",
    "    def typicalDistanceDistribution(self, sample=-1):\n",
    "\n",
    "        all_shortest_paths = []\n",
    "        if sample == -1:\n",
    "            #dictionary of dictionaries dict[source][target] = path\n",
    "            for source, destinations in nx.algorithms.shortest_path(self.G).items():\n",
    "                for destination, path in destinations.items():\n",
    "                    all_shortest_paths.append(path)\n",
    "        else:\n",
    "            sources = random.choices(list(self.G.nodes), k=sample)\n",
    "            targets = random.choices(list(self.G.nodes), k=sample)\n",
    "            for i in range(sample):\n",
    "                all_shortest_paths.append(nx.algorithms.shortest_path(self.G, sources[i], targets[i]))\n",
    "\n",
    "        # calculate pmf\n",
    "        pmf = {}\n",
    "        numberOfPaths = 0 #if sample > 0, then this will end up being equal to sample\n",
    "        for path in all_shortest_paths:\n",
    "            if (len(path)-1) in pmf:\n",
    "                pmf[len(path)-1] += 1\n",
    "            else: \n",
    "                pmf[len(path)-1] = 1\n",
    "            numberOfPaths += 1\n",
    "\n",
    "        print(numberOfPaths)\n",
    "\n",
    "        #normalize the histogram (paths currently double counted)\n",
    "        for key in pmf.keys():\n",
    "            pmf[key] = pmf[key] / numberOfPaths\n",
    "\n",
    "        assert abs(sum([v for v in pmf.values()]) - 1) < 0.00001, \"pmf does not sum to one!!\"\n",
    "\n",
    "        return pmf\n",
    "\n",
    "    '''\n",
    "    Returns size of largest connected component (giant components)\n",
    "    Note: Strictly speaking, we assume the GRG is highly connected, that is, as n -> \\inf, \n",
    "    liminf of the ( size of the largest connected component / size of network) > 0.\n",
    "    '''\n",
    "    def getSizeOfGiantComponent(self):\n",
    "        # get sorted list of size of all connected components\n",
    "        component_sizes = [len(c) for c in sorted(nx.connected_components(self.G), key=len, reverse=True)]\n",
    "        return component_sizes[0]\n",
    "\n",
    "    '''\n",
    "    store the networkx graph object\n",
    "    '''\n",
    "    def dumpGraph(self, fp='default'):\n",
    "        import pickle\n",
    "\n",
    "        if fp == 'default':\n",
    "            fp = datetime.now().strftime(\"%H:%M:%S\") + \".graph\"\n",
    "        elif not \".graph\" in fp:\n",
    "            fp = fp + \".graph\"\n",
    "\n",
    "        with open(fp, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "            \n",
    "#ideetje al collapsen na de edge toe te voegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 6721.64it/s]\n"
     ]
    }
   ],
   "source": [
    "pam = graph(2, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:00<00:00, 3986.56it/s]\n"
     ]
    }
   ],
   "source": [
    "pam.growCoex(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pam.getSizeOfGiantComponent()\n",
    "\n",
    "#hello!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collapseGraph2(self):\n",
    "    adj = nx.to_numpy_array(self.G_repr).astype('int8')\n",
    "    adjslice = np.lib.stride_tricks.as_strided(adj, shape=(self.current_timestep,self.current_timestep,self.m,self.m), strides=(2*self.current_timestep*self.m,self.m,self.current_timestep*self.m,1))\n",
    "    newadj = np.zeros((self.current_timestep,self.current_timestep))\n",
    "    for i in range(self.current_timestep):\n",
    "        for j in range(self.current_timestep):\n",
    "            newadj[i][j] = np.max(adjslice[i][j])\n",
    "    self.G = nx.from_numpy_array(newadj)\n",
    "        \n",
    "def merge_nodes(G,nodes, new_node, attr_dict=None, **attr):\n",
    "    \n",
    "    G.add_node(new_node, attr_dict, **attr) # Add the 'merged' node\n",
    "    \n",
    "    for n1,n2,data in G.edges(data=True):\n",
    "        # For all edges related to one of the nodes to merge,\n",
    "        # make an edge going to or coming from the `new gene`.\n",
    "        if n1 in nodes:\n",
    "            G.add_edge(new_node,n2,data)\n",
    "        elif n2 in nodes:\n",
    "            G.add_edge(n1,new_node,data)\n",
    "    \n",
    "    for n in nodes: # remove the merged nodes\n",
    "        G.remove_node(n)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8cdcb69b8cab893b96292d95a52a09a5df32ebb6fdbe975b9a87c47ea23fe8a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('Clean': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
